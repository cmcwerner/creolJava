\documentclass[12pt]{article}%[preprint],%a4paper,English
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{framed}

\pdfoutput=1

\input{preamble}
\definecolor{shadecolor}{rgb}{0.9,0.9,0.9}
\newcommand{\Blue}[1] {\textcolor{blue}{#1}}%{\textsf{#1}}%
\input{definitions}    
\input{opsemDefs}
%
\newcommand{\knip}{\vspace{-1.5mm}}
\newcommand{\OLDFOOT}[1]{}%{\OO{TODO: #1}}
%\newcommand{\IFLONG}[1]{}%{\OO{TODO: #1}}
\newcommand{\TODO}[1]{}%{\OO{TODO: #1}}
\newcommand{\oo}{object-oriented\xspace}%{\textsf{#1}}%
\newcommand{\get}{get\xspace}%{\textsf{#1}}%
\renewcommand{\NEW}[1]{#1}%{\Blue{#1}}%{\textcolor{blue}{\textit {#1}}}%{\textsf{#1}}% {#1}
%\renewcommand{\RED}[1]{\textcolor{magenta}{#1}}


%\begin{frontmatter}

\begin{document}

\title{On detecting over-eager concurrency  in  asynchronously communicating  concurrent objects%
\thanks{This work was done in the context of the EU projects
   FP7-610582  \emph{Envisage: Engineering Virtualized Services}
    (\texttt{http://www.envisage-project.eu}) and
FP7-ICT-2013-X \emph{UpScale: From Inherent Concurrency to Massive 
Parallelism through Type-based Optimizations}
  (\texttt{http://www.upscale-project.eu}).}}

\author{Charlie McDowell and Olaf Owe\\
 \small{University of California, Santa Cruz, Dept.\ of Computer Science, USA, }\\
 \small{and University of Oslo, Dept.\  of Informatics Norway} 
 }
\date{\today}
\maketitle

\lstset{language=ABS}
\lstset{basicstyle=\ttfamily}
\ignore{
\lstset{backgroundcolor=\color{codebg}}
\lstset{frame=single}
\lstset{framesep=10pt}
\lstset{rulecolor=\color{codeframe}}
\lstset{upquote=true}

}

\lstset{emph={awk}, emphstyle=\textbf}

\section{Introduction}
Here ... flushing cycles

Creol (and others) have suggested the use of concurrent objects
communicating via asynchronous method calls and futures, as a pathway
to better reasoning about concurrent systems. The communication and
synchronization model of Creol simplifies deadlock detection, allows
for ...

These advantages do not come without a price.  Although not unique to
programs created using Creol style synchronization, this programming
style does make it quite easy to create programs that are semantically
correct but that fail due to over eager creation of suspended method
calls.


We ignore flooding caused by direct recursion,
since this is not considered a cuncurrency problem.
\section{Flooding Cycles}

As a motivating example we will
consider  versions of the publish/subscribe example.
%taken from \cite{din14jlap}.
Clients may  \lstinline{subscribe} to a service object
and the service object will ensure 
that subscribing objects receive information about ``news''.
Clients are notified by news by 
%The interface of Clients contains
 the   \lstinline{signal} method.
%for this purpose. 
%Clints call \lstinline{subscribe} on the 
The service object is using a number of proxies to 
handle all the clients and is using  an underlying news producer
to obtain news. The service object is using futures to avoid
being delayed by waiting for news to be available,
thus it may continously respond to clients.
The  interfaces of these units are given 
in figure \ref{example-subscr-interfaces}.

\begin{figure}
%Example
\begin{abs}
data News=E1|E2|E3|E4|E5|None;    $\hfill$ // example of different news
interface ServiceI{
  Void subscribe(ClientI cl);     $\hfill$ // called by Clients
  Void produce()}                 $\hfill$ // called by Proxies
interface ProxyI{
  ProxyI add(ClientI cl);         $\hfill$ // called by Service objects
  Void publish(Fut<News> fut)}    $\hfill$ // called by Service objects
interface ProducerI{
  News detectNews()}              $\hfill$ // called by Service objects
interface NewsProducerI{
  Void add(News ns);              $\hfill$ // called by main when news arrive
  News getNews();                 $\hfill$ // called by Producer objects
//  List<News>getRequests()}     // not used !
interface ClientI{
  Void signal(News ns)}           $\hfill$ // called by Proxies
\end{abs}
\caption{\label{example-subscr-interfaces}
The interfaces to complete the subscription example.}
\end{figure}
 %=========================================

A high-level Creol implementation of 
%the example of
 the publish/subscribe model is given in 
figure \ref{example-subscr} and is taken from Din and Owe\cite{din14jlap}.


\begin{figure}
%Example
\begin{abs}
class Service(Intlimit,NewsProducerInp) implements ServiceI{
  ProducerI prod;ProxyIproxy;ProxyIlastProxy;
  { prod := new Producer(np); 
    proxy:= new Proxy(limit,this);lastProxy:=proxy;this!produce()}
  Void subscribe(ClientIcl){lastProxy:=lastProxy.add(cl)}
  Void produce(){var Fut<News>fut:=prod!detectNews();proxy!publish(fut)}}

class Proxy(Intlimit,ServiceIs) implements ProxyI{
  List<ClientI> myClients:=Nil;ProxyInextProxy;
  ProxyI add(ClientIcl){
    var ProxyI lastProxy=this;
    if length(myClients)<limit then myClients:=appendright(myClients,cl)
    else if nextProxy==null then nextProxy:= new Proxy(limit,s) fi;
             lastProxy:=nextProxy.add(cl) fi;
    put lastProxy}
  Void publish(Fut<News>fut){
    var News ns=None;
    ns =fut.get; myClients!signal(ns);
    if nextProxy==null then s!produce() else nextProxy!publish(fut) fi}}

class Producer(NewsProducerI np) implements ProducerI{
  News detectNews(){
    News news:=None;
    news:=np.getNews(); put news}}
class NewsProducer implements NewsProducerI{
  List<News>requests:=Nil;
  Void add(News ns){requests:=appendright(requests,ns)}
  News getNews(){
    var News firstNews:=None; await requests /= Nil;
    firstNews := head(requests);requests:=tail(requests); put firstNews}
 }

class Client implements ClientI{
  Newsnews:=None;
  Void signal(News ns){news:=ns}}

\end{abs}
\caption{\label{example-subscr}
A simple subscription example.}
\end{figure}
 %=========================================

Modifying Client and Proxy as shown in figure \ref{example-subscr-flooding}, results in a program that will flood the system with suspended calls. 
The changes are at lines 9 and 14 in the revised code.
The change is to shift requiring the actual news to have arrived from the Proxy (\lstinline{ns=fut.get; myClients!signal(ns);})
to the Client (\lstinline{news:=fut.get}).


\begin{figure}
%Example
\begin{abs}
class Proxy(Intlimit,ServiceIs) implements ProxyI{
  List<ClientI> myClients:=Nil;ProxyInextProxy;
  ProxyIadd(ClientIcl){
    var ProxyIlastProxy=this;
    if length(myClients)<limit then myClients:=appendright(myClients,cl)
    else if nextProxy==null then nextProxy:= new Proxy(limit,s) fi;
    lastProxy:=nextProxy.add(cl) fi; put lastProxy}
  Void publish(Fut<News>fut){
    myClients!signal(fut);
    if nextProxy==null then s!produce() else nextProxy!publish(fut) fi}}

class Client implements ClientI{
  News news:=None;
  Void signal(Fut<News> fut){news:=fut.get}}

\end{abs}
\caption{\label{example-subscr-flooding}
A flooding variation of the subscription example.}
\end{figure}
 %=========================================

This seemingly minor change, and one that would even seem to make sense in the interest of maximizing concurrency, is in
fact ``too much.'' We might naively take it even one step further and have the client instead do 
\lstinline{news:=await(fut)}, 
which has the additional advantage of allowing the Client to process the news items as they become available, rather then in
the order that the futures were received. In either case, the following sequence of calls can occur, which constitute a
flooding cycle (see definition \ref{flooding-cycle}).
\\

{\small
\samepage
%\begin{center}\begin{flushleft}%{verbatim}
\indent\lstinline{Service.produce} asynchronously calls \lstinline{Producer.detectNews}
\\
\indent\lstinline{Service.produce} asynchronously calls \lstinline{Proxy.publish}
\\
\indent\lstinline{Proxy.publish} asynchronously calls \lstinline{Client.signal}
\\
\indent\lstinline{Proxy.publish} asynchronously calls \lstinline{Service.produce}
%\end{flushleft}\end{center}%{verbatim}
}\\

\noindent
Each pass around this cycle, the asynchronous call to \lstinline{Proxy.publish} is processed as part of the cycle (step 3).
However, each pass around this cycle also spawns an asynchronous call to  \lstinline{Producer.detectNews} that is not processed as part of this cycle,
nor is there any attempt to synchronize this cycle with the completion of those calls to  \lstinline{Producer.detectNews}.
Depending upon the speed of
execution of the code along the path of the cycle, such a cycle can create an unbounded number of suspended calls to
\lstinline{Producer.detectNews}.

We call such sequences flooding-cycles. In this paper we present an algorithm to statically identify
programs that contain flooding-cycles. This approach is conservative in that if it reports that a program is free from
flooding-cycles then it is indeed free of such cylces, however, it may report flooding-cycles that are in fact bounded by
program logic, not amenable to static analysis. It will also report flooding-cycles that do not in practice produce an
increasing number of unprocessed calls due to the execution speed of the flooding-cycle. 

A flooding-cycle must always be racing against one or more specific asynchronous calls, either trivial calls (no waiting on
any future from the call) or calls where the resulting future is not read in the cycle, although the future may be passed
to a separate asynchronous call where it is read.  

The version of the program in figure \ref{example-subscr} has a flooding-cycle (cycle B in figure \ref{graph-orig}) 
that is racing against the \lstinline{Client.signal} calls
generated in \lstinline{Proxy.publish}. This will not cause a problem, provided the Client objects are able to process these signal
calls at least as fast as they are being generated. Our algorithm will alert the programmer to this situation, and the
programmer can determine if there is a real problem here, possibly with the aid of some additional program
instrumentation.  

In this case, the flooding-cycle will not create a flood for two reasons that are beyond the ability of our current approach to detect.
First, this cycle is in fact bounded by program logic. The cycle is walking down a finite chain of Proxy objects.
Second, after a finite number of times around the cycle the code will branch and make a pass around the cycle that includes the 
\lstinline{get}
(cycle A in figure \ref{graph-orig})
which results in a delay for more news to actually arrive, thus limiting the speed of cycle A.

The version of the program in figure \ref{example-subscr-flooding}
results in the graph shown in figure \ref{graph-modified}. This second graph is the same as that in figure \ref{graph-orig}
except that the \lstinline{get} node is now in the  \lstinline{Client.signal}
method (not shown in the graph) and there is no \lstinline{get} in cycle A. 
The result is that cycle A in the modified program
is a flooding cycle that is racing against both the
\lstinline{Client.signal} calls and also against the
\lstinline{Producer.detectNews} calls.  This is because rather than
wait in \lstinline{Proxy.publish} for the news to actually be produced
as in the first version (\lstinline{ns=fut.get;}),
\lstinline{Proxy.publish} instead simply passes the future out to
another asynchronous call (\lstinline{myClients!signal(fut);}),
eliminating any progress coordination between cycle A and the
\lstinline{Client.signal} calls. Cycle A in this version of the program is more likely to be a
problem because it is not dependent simply on execution speed of some
code but is dependent upon the arrival rate of news items and in
practice will always result in the number of unprocessed calls quickly
growing to system limits.

\section{Identifying Flooding Cycles}

\begin{definition}
\label{flooding-cycle}
A \emph{flooding-cycle} is an execution cycle 
containing a call statement
%involving one or more asynchronous calls
%such that for at least one of those calls,  call it $o.m()$ occurring
 at a given program location, such that 
this statement may produce an unbounded number of  method calls  
before any of them %invocation of  $o.m()$
 has been completed.
\end{definition}%

Flooding of this kind may depend on the relative
speed of different objects, and  may be difficult to detect even
by testing of complete systems, due to their inherent
non-deterministic nature.  They may show up for instance at times when
the system load is high.

Flooding cycles that depend on unfair scheduling
may be avoided with fair scheduling of concurrent activity and
fair scheduling of  tasks inside one unit.
Flooding cycles that exist even with fair scheduling
are more serious, indicating bad programming.
We call such flooding \emph{strong flooding}.
%inherent, serious

\ignore{
%\section{Definition of Strong Flooding Cycles} %p
\begin{definition}
\label{strong-flooding-cycle}
A \emph{strong flooding-cycle} is an execution cycle 
involving one or more asynchronous calls
such that for at least one of those calls, call it $o.m()$,
an unbounded number of the calls to  $o.m()$ may be produced by the cycle
before any invocation of  $o.m()$ has been completed,
even with fair scheduling between concurrent units and 
(enabled) tasks within each unit.
\end{definition}}

The top-level view of an algorithm to detect flooding-cycles is shown in figure \ref{flow-analysis}.
We first create a control flow graph for each method where the nodes are method start nodes, method calls, \emph{get} statements, 
\emph{await} statements,
or \emph{put} statements (including implicit \emph{put} statements at the end of Void methods)\footnote{
Synchronous method calls will be represented as an asyncrhonous method call followed immediately by a \emph{get}.}.
All other statements are ignored. 
In addition, the nodes are of two types,
synchronous, or asynchronous. Synchronous nodes are \emph{get} statements or \emph{await} statements.

\begin{figure}
\begin{shaded}
\begin{enumerate}
\item Build the individual control flow graphs for each method including a start node, and a node for each call, \emph{get}, \emph{await}, 
and \emph{put} statements.
\item Add call edges from call nodes to the start node of a copy of the corresponding method cfg, unless the call is recursive, in which case
create a call edge to the approriate start node. Assign each call node a unique label (e.g. the line number from the program). 
%Assign the put(s) in the copy the same label as the label for the call node.
\item Use flow analysis to compute the \emph{put} edges from \emph{put}s to \emph{get}/\emph{await}. (What is going to happen with more complex examples
where there are multiple \emph{put}s that might reach a given \emph{get}?)
\item Remove any flow egdes leading into get nodes.
\item Identify any cycles in the graph.
\item Compute the calls and comps sets for each cycle to identify flooding-cycles using algorithm xx.
\end{enumerate}\end{shaded}%
\caption{\label{flow-analysis}
Top Level Algorithm for Detecting Flooding-Cycles}
\end{figure}

In step 2 we connect the cfgs for each method with call edges expanding all non-recursive calls so that we can
associate a specific call with a specific get/put. Note that we do not distinguish between objects, only classes.

In step 3 we add edges from \emph{put} statements to \emph{get} or \emph{await} statements that block on the value for that future.
\footnote{If we have the ambition of ensuring that 
there is no flooding when the algorithm finds none,
we must ensure that a ``get'' actually waits for the future
(``must instead of ``might'').}

In step 4 we remove flow edges into get nodes. For execution to continue past a get, it must have also passed through the
method completing the future, thus removing the edge does not eliminate any key cycles. (See thm xxx.)

In step 5 we identify any cycles in the graph.

In step 6 we apply the algorithm in figure xx to identify any flooding cycles.
If there is a cycle that creates futures (including implicit Void futures for trivial calls) that are not read
in the cycle, then there is a flooding-cycle with respect to the call that produced the unread future. 
(I guess this is where we introduce a theorem.)

%=======================================================
\subsection{Computing the call and comp sets (step 6)}

\textbf{Assumptions:}

\begin{itemize}
\item
The calls in the graph are labeled, 
say numbered by their textual occurrence in the (sub)program.
\item
 We consider one cycle (at a time),
ignoring any external call initiating the cycle.
%\item
%If the same method is called several times from within the cycle,
%we include a copy of its body for each call.
%Thus each copy of a  method body has  at most  one caller from within the cycle.
\item
We assume a finite graph (even after expansion).
\item 
A  \emph{put} node of a copy of a method body, is marked with the same label $n$ as the label of the
caller, marking that the call is completed. (Note: This may change with each cycle due to possible recursion.)
\item
We assume each \emph{get}  node,
and each \emph{put} node, possibly outside the cycle, 
can be traced back to a unique call $n$ creating the call,
and we mark each  \emph{get} node and each  \emph{put} node  with the corresponding call  $n$, marking that the call is 
completed.
Note, in this analysis other parts of the program graph may be needed!
\item
Blocking calls are split into an async call $n$ and a (matching) \emph{get}
marked with  $n$.
\item
We treat blocking self-calls specially,
by not including an edge from the call node to the get node,
but instead  in-lining  the copy of the method
 (with an arrow to its
start node, and an arrow from each  \emph{put} node
back to the next statement).
\item
Boolean \emph{await} statements are represented as nodes in the graph
(since they may affect method completion).

\end{itemize}
\textbf{Analysis:}
The analysis considers one cycle (at a time)
together with surrounding parts of the program graph.
The analysis will collect sets of calls $n$ from the cycle and call completions,
in  the cycle, or even outside  the cycle when  reachable from the cycle without suspensions or blocking,
or  when a predecessor of  a \emph{get} is related to a call in the cycle.
The analysis, uses two sets, denoted $calls$ and $comps$.

\begin{figure}
\begin{shaded}
\begin{itemize}
\item For each call $n$ in the cycle add $n$ to $calls$.
\item For each \emph{get} node  marked   $n$ in the cycle add   $n$ to  $comps$.
%\item For each \emph{put} node  marked   $n$ in the cycle  add   $n$ to  $comps$.
%\item  For each \emph{put} node marked   ${n}$ reachable along flow edges from the cycle, 
%without going through \emph{await} or  \emph{get} nodes,
% add   ${n}$ to  $comps$.
\item For each node, $N_i$, with flow edges leaving the cycle where the cycle edge is an async call edge,%
\footnote{could we say:  
        For each call edge in the cycle,  leaving a node, $N_i$ with flow edges leaving the cycle }
% ie not the off cycle edge in Ex2 from O.m to A.a
if all flow-edge-only paths starting from $N_i$ lead to a put %Will it work to include call edges AFTER the first edge? See ex 9.
%before encountering \emph{await} or \emph{get} nodes, % no need for this now because there are NO flow edges into get nodes
then add ${n}$ to $comps$,
%see Ex7 for multiple paths one that reaches the put and one that does not resulting in a flood of calls to B.
where ${n}$ is the label on the puts. % I assert all such puts should have the same label. 
In addtion, if there is a call node $c$ on any flow-edge, off-cycle path from $N_i$ to the first put, unlabeled-get, or await on the path,
% can there be an unlabeld-get??? or just gets with labels that are not in calls. That would seem to suggest an unexecutable path.
then add $c$ to calls, and
%There is a problem here. get/await seem to end the paths so do we ever go past a get in such cases?
%I think the answer is yes. I'm thinking we need to treat a get that is matched to a specific put in the graph differently and ALWAYS
%remove the flow edge INTO the get, requiring the cycle to go around through the put node. In these cases the get would always be essentially a noop.
%Then gets that can't be matched to a specific put are treated as blocking and the end of a path as far as the analysis goes.
%If sticking with the labeling idea, a get with a label passes immediately and a get with no label ends the path.
%I suppose a get with no label on a cycle would be treated as always passing, but adding nothing to comps.
if there is a get with label $g$ on every such path, then add $g$ to comps.
%\item  For each \emph{get}  marked   ${n}$ leading to a \emph{put}  node related to a call in the cycle, add   ${n}$ to  $comps$.
\item For each put node, $P_i$, in the cycle with more than one output edge, need to follow all paths off of the cycle following
all types of edges to the ends of the paths (note the flow edges INTO get nodes will have been removed) adding ${n}$ to $calls$ for
each call node encountered and ${n}$ to $comps$ for each put node encountered. (Note this flow will never encounter a get except
from a put which will have already added the appropriate value to $comps$.)
\end{itemize}
\end{shaded}
\caption{\label{call-cons-analysis}
Algorithm to compute the call and comp sets for a cycle.}
\end{figure}

\begin{theorem}
The cycle is \emph{flooding wrt a call} $n$ if 
$n\in (calls -comps)$.
\end{theorem}

\subsection{Applying the Algorithm to the example program}


\begin{figure}[t]
\includegraphics[width=15cm]{graphOrig}
\caption{\label{graph-orig}
The graph and call/comp sets for the original version of the program (figure \ref{example-subscr}).
}
\end{figure}

\begin{figure}[t]
\includegraphics[width=15cm]{graphModified}
\caption{\label{graph-modified}
The graph and call/comp sets for the modified version of the program (figure \ref{example-subscr-flooding}).
}
\end{figure}


Figures \ref{graph-orig} and \ref{graph-modified} show the call and comp sets
for the two versions of the producer consumer problem above. To conserve space, all method names are abbreviated to the
first letter of the class and the first letter of the method except that we use X for the class Proxy it further disambiguate it from Producer. 
For example, Producer.detectNews is Pd and Proxy.publish is written Xp.

In figure \ref{graph-orig} we see that Cs (Client.signal) is being flooded by each of the three cycles. 
In practice these do not produce floods because in this implementation, the amount of work required by the
Client to complete a signal call is trivial and thus the Client objects easily keep up with the calls. Also, the rate of execution for 
each of the cycles is
limited by the actual arrival of news items from the NewsProducer, which further limits the rate at which this cycle generates asynchronous calls to
CLient.signal. (Is this an example of weak flooding?)

In the modified version of the program as reflected in figure \ref{graph-modified} there is an additional flood between cycle A and
Pd (Producer.detectNews). This flooding-cycle is serious, and in practice will flood the system almost immediately.
Unlike in version 1, there is no \emph{get} regulating the speed at which cycle A cycles. Furthermore, the Pd calls are dependent upon the
arrival of news items not simply limited by processor execution speed.

\subsection{Weak and strong flooding}
When a cycle floods with respect to a call $o.m$,
we say that we have \emph{strong flooding} 
when the method contains an  await or get node
(not resolved in the context of the cycle),
otherwise \emph{weak flooding}.
Strong flooding indicates a serious flooding case,
while weak flooding typically indicates flooding 
that is harmless, given underlying fairness of concurrent objects
and  fair scheduling of tasks within an object. 
%Weak flooding of several calls to the same object could cause serious flooding.

The first version of the subscription example
has weak flooding of client calls (\emph{signal}),
whereas the second has strong flooding both wrt
to client calls and  to \emph{detectNews} calls.


\bibliographystyle{abbrv}
%\bibliographystyle{alpha} 
\bibliography{creol,ref}
%\bibliography{extracted}


\end{document}
============================= end of file ====================================


output sets written after each statement, label before colon
  Sp  3 
1:Pd  1,3
2:Xp  1,2,3
           put-Sp
  Xp  1,2,3
  Get 1,~1,2,3
3:Cs  1,~1,2,~2,3
4:Sp  1,~1,2,~2,3
          put-Xp
