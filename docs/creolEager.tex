\documentclass[12pt]{article}%[preprint],%a4paper,English
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{framed}

\pdfoutput=1

\input{preamble}
\definecolor{shadecolor}{rgb}{0.9,0.9,0.9}
\newcommand{\Blue}[1] {\textcolor{blue}{#1}}%{\textsf{#1}}%
\input{definitions}    
\input{opsemDefs}
%
\newcommand{\knip}{\vspace{-1.5mm}}
\newcommand{\OLDFOOT}[1]{}%{\OO{TODO: #1}}
%\newcommand{\IFLONG}[1]{}%{\OO{TODO: #1}}
\newcommand{\TODO}[1]{}%{\OO{TODO: #1}}
\newcommand{\oo}{object-oriented\xspace}%{\textsf{#1}}%
\newcommand{\get}{get\xspace}%{\textsf{#1}}%
\renewcommand{\NEW}[1]{#1}%{\Blue{#1}}%{\textcolor{blue}{\textit {#1}}}%{\textsf{#1}}% {#1}
%\renewcommand{\RED}[1]{\textcolor{magenta}{#1}}


%\begin{frontmatter}

\begin{document}

\title{On detecting over-eager concurrency  in  asynchronously communicating  concurrent objects%
\thanks{This work was done in the context of the EU projects
   FP7-610582  \emph{Envisage: Engineering Virtualized Services}
    (\texttt{http://www.envisage-project.eu}) and
FP7-ICT-2013-X \emph{UpScale: From Inherent Concurrency to Massive 
Parallelism through Type-based Optimizations}
  (\texttt{http://www.upscale-project.eu}).}}

\author{Charlie McDowell and Olaf Owe\\
 \small{University of California, Santa Cruz, Dept.\ of Computer Science, USA, }\\
 \small{and University of Oslo, Dept.\  of Informatics Norway} 
 }
\date{\today}
\maketitle

\lstset{language=ABS}
\lstset{basicstyle=\ttfamily}
\ignore{
\lstset{backgroundcolor=\color{codebg}}
\lstset{frame=single}
\lstset{framesep=10pt}
\lstset{rulecolor=\color{codeframe}}
\lstset{upquote=true}

}

\lstset{emph={awk}, emphstyle=\textbf}

\section{Introduction}
Here ... flushing cycles

Creol (and others) have suggested the use of concurrent objects
communicating via asynchronous method calls and futures, as a pathway
to better reasoning about concurrent systems. The communication and
synchronization model of Creol simplifies deadlock detection, allows
for ...

These advantages do not come without a price.  Although not unique to
programs created using Creol style synchronization, this programming
style does make it quite easy to create programs that are semantically
correct but that fail due to over eager creation of suspended method
calls.


We ignore flooding caused by direct recursion,
since this is not considered a cuncurrency problem.
\section{Flooding Cycles}

As a motivating example we will
consider  versions of the publish/subscribe example.
%taken from \cite{din14jlap}.
Clients may  \lstinline{subscribe} to a service object
and the service object will ensure 
that subscribing objects receive information about ``news''.
Clients are notified by news by 
%The interface of Clients contains
 the   \lstinline{signal} method.
%for this purpose. 
%Clints call \lstinline{subscribe} on the 
The service object is using a number of proxies to 
handle all the clients and is using  an underlying news producer
to obtain news. The service object is using futures to avoid
being delayed by waiting for news to be available,
thus it may continously respond to clients.
The  interfaces of these units are given 
in figure \ref{example-subscr-interfaces}.

\begin{figure}
%Example
\begin{abs}
data News=E1|E2|E3|E4|E5|None;    $\hfill$ // example of different news
interface ServiceI{
  Void subscribe(ClientI cl);     $\hfill$ // called by Clients
  Void produce()}                 $\hfill$ // called by Proxies
interface ProxyI{
  ProxyI add(ClientI cl);         $\hfill$ // called by Service objects
  Void publish(Fut<News> fut)}    $\hfill$ // called by Service objects
interface ProducerI{
  News detectNews()}              $\hfill$ // called by Service objects
interface NewsProducerI{
  Void add(News ns);              $\hfill$ // called by main when news arrive
  News getNews();                 $\hfill$ // called by Producer objects
//  List<News>getRequests()}     // not used !
interface ClientI{
  Void signal(News ns)}           $\hfill$ // called by Proxies
\end{abs}
\caption{\label{example-subscr-interfaces}
The interfaces to complete the subscription example.}
\end{figure}
 %=========================================

A high-level Creol implementation of 
%the example of
 the publish/subscribe model is given in 
figure \ref{example-subscr} and is taken from Din and Owe\cite{din14jlap}.


\begin{figure}
%Example
\begin{abs}
class Service(Intlimit,NewsProducerInp) implements ServiceI{
  ProducerI prod;ProxyIproxy;ProxyIlastProxy;
  { prod := new Producer(np); 
    proxy:= new Proxy(limit,this);lastProxy:=proxy;this!produce()}
  Void subscribe(ClientIcl){lastProxy:=lastProxy.add(cl)}
  Void produce(){var Fut<News>fut:=prod!detectNews();proxy!publish(fut)}}

class Proxy(Intlimit,ServiceIs) implements ProxyI{
  List<ClientI> myClients:=Nil;ProxyInextProxy;
  ProxyI add(ClientIcl){
    var ProxyI lastProxy=this;
    if length(myClients)<limit then myClients:=appendright(myClients,cl)
    else if nextProxy==null then nextProxy:= new Proxy(limit,s) fi;
             lastProxy:=nextProxy.add(cl) fi;
    put lastProxy}
  Void publish(Fut<News>fut){
    var News ns=None;
    ns =fut.get; myClients!signal(ns);
    if nextProxy==null then s!produce() else nextProxy!publish(fut) fi}}

class Producer(NewsProducerI np) implements ProducerI{
  News detectNews(){
    News news:=None;
    news:=np.getNews(); put news}}
class NewsProducer implements NewsProducerI{
  List<News>requests:=Nil;
  Void add(News ns){requests:=appendright(requests,ns)}
  News getNews(){
    var News firstNews:=None; await requests /= Nil;
    firstNews := head(requests);requests:=tail(requests); put firstNews}
 }

class Client implements ClientI{
  Newsnews:=None;
  Void signal(News ns){news:=ns}}

\end{abs}
\caption{\label{example-subscr}
A simple subscription example.}
\end{figure}
 %=========================================

Modifying Client and Proxy as shown in figure \ref{example-subscr-flooding}, results in a program that will flood the system with suspended calls. 
The changes are at lines 9 and 14 in the revised code.
The change is to shift requiring the actual news to have arrived from the Proxy (\lstinline{ns=fut.get; myClients!signal(ns);})
to the Client (\lstinline{news:=fut.get}).


\begin{figure}
%Example
\begin{abs}
class Proxy(Intlimit,ServiceIs) implements ProxyI{
  List<ClientI> myClients:=Nil;ProxyInextProxy;
  ProxyIadd(ClientIcl){
    var ProxyIlastProxy=this;
    if length(myClients)<limit then myClients:=appendright(myClients,cl)
    else if nextProxy==null then nextProxy:= new Proxy(limit,s) fi;
    lastProxy:=nextProxy.add(cl) fi; put lastProxy}
  Void publish(Fut<News>fut){
    myClients!signal(fut);
    if nextProxy==null then s!produce() else nextProxy!publish(fut) fi}}

class Client implements ClientI{
  News news:=None;
  Void signal(Fut<News> fut){news:=fut.get}}

\end{abs}
\caption{\label{example-subscr-flooding}
A flooding variation of the subscription example.}
\end{figure}
 %=========================================

This seemingly minor change, and one that would even seem to make sense in the interest of maximizing concurrency, is in
fact ``too much.'' We might naively take it even one step further and have the client instead do 
\lstinline{news:=await(fut)}, 
which has the additional advantage of allowing the Client to process the news items as they become available, rather then in
the order that the futures were received. In either case, the following sequence of calls can occur, which constitute a
flooding cycle (see definition \ref{flooding-cycle}).
\\

{\small
\samepage
%\begin{center}\begin{flushleft}%{verbatim}
\indent\lstinline{Service.produce} asynchronously calls \lstinline{Producer.detectNews}
\\
\indent\lstinline{Service.produce} asynchronously calls \lstinline{Proxy.publish}
\\
\indent\lstinline{Proxy.publish} asynchronously calls \lstinline{Client.signal}
\\
\indent\lstinline{Proxy.publish} asynchronously calls \lstinline{Service.produce}
%\end{flushleft}\end{center}%{verbatim}
}\\

\noindent
Each pass around this cycle, the asynchronous call to \lstinline{Proxy.publish} is processed as part of the cycle (step 3).
However, each pass around this cycle also spawns an asynchronous call to  \lstinline{Producer.detectNews} that is not processed as part of this cycle,
nor is there any attempt to synchronize this cycle with the completion of those calls to  \lstinline{Producer.detectNews}.
Depending upon the speed of
execution of the code along the path of the cycle, such a cycle can create an unbounded number of suspended calls to
\lstinline{Producer.detectNews}.

We call such sequences flooding-cycles. In this paper we present an algorithm to statically identify
programs that contain flooding-cycles. This approach is conservative in that if it reports that a program is free from
flooding-cycles then it is indeed free of such cylces, however, it may report flooding-cycles that are in fact bounded by
program logic, not amenable to static analysis. It will also report flooding-cycles that do not in practice produce an
increasing number of unprocessed calls due to the execution speed of the flooding-cycle. 

A flooding-cycle must always be racing against one or more specific asynchronous calls, either trivial calls (no waiting on
any future from the call) or calls where the resulting future is not read in the cycle, although the future may be passed
to a separate asynchronous call where it is read.  

The version of the program in figure \ref{example-subscr} has a flooding-cycle (cycle B in figure \ref{graph-orig}) 
that is racing against the \lstinline{Client.signal} calls
generated in \lstinline{Proxy.publish}. This will not cause a problem, provided the Client objects are able to process these signal
calls at least as fast as they are being generated. Our algorithm will alert the programmer to this situation, and the
programmer can determine if there is a real problem here, possibly with the aid of some additional program
instrumentation.  

In this case, the flooding-cycle will not create a flood for two reasons that are beyond the ability of our current approach to detect.
First, this cycle is in fact bounded by program logic. The cycle is walking down a finite chain of Proxy objects.
Second, after a finite number of times around the cycle the code will branch and make a pass around the cycle that includes the 
\lstinline{get}
(cycle A in figure \ref{graph-orig})
which results in a delay for more news to actually arrive, thus limiting the speed of cycle A.

The version of the program in figure \ref{example-subscr-flooding}
results in the graph shown in figure \ref{graph-modified}. This second graph is the same as that in figure \ref{graph-orig}
except that the \lstinline{get} node is now in the  \lstinline{Client.signal}
method (not shown in the graph) and there is no \lstinline{get} in cycle A. 
The result is that cycle A in the modified program
is a flooding cycle that is racing against both the
\lstinline{Client.signal} calls and also against the
\lstinline{Producer.detectNews} calls.  This is because rather than
wait in \lstinline{Proxy.publish} for the news to actually be produced
as in the first version (\lstinline{ns=fut.get;}),
\lstinline{Proxy.publish} instead simply passes the future out to
another asynchronous call (\lstinline{myClients!signal(fut);}),
eliminating any progress coordination between cycle A and the
\lstinline{Client.signal} calls. Cycle A in this version of the program is more likely to be a
problem because it is not dependent simply on execution speed of some
code but is dependent upon the arrival rate of news items and in
practice will always result in the number of unprocessed calls quickly
growing to system limits.

\section{Identifying Flooding Cycles}

%\section{Definition of Flooding Cycles}
\begin{definition}
\label{flooding-cycle}
A \emph{flooding-cycle} is an execution cycle 
involving one or more asynchronous calls
such that for at least one of those calls, call it $o.m()$,
an unbounded number of the calls to  $o.m()$ may be produced by the cycle
before any invocation of  $o.m()$ has been completed.
\end{definition}%
\footnote{So iteration of the cycle \emph{ call o.m(); call o.m(); get (for one of these calls only);} will produce an unbounded number of uncompleted o.m-calls, but is NOT considered a flooding cycle since some of the call will complete.
However, we do not want to count too much, so this might  be the best we can deal with, unless we talk about calls of a given  program location 
 giving rise to 
unboundedness. A definition we could statically analyse, could possibly be: 
\begin{definition}
\label{flooding-cycle2}
A \emph{flooding-cycle} is an execution cycle 
containing a call statement
%involving one or more asynchronous calls
%such that for at least one of those calls,  call it $o.m()$ occurring
 at a given program location, such that 
this statement may produce an unbounded number of  method calls  
before any of them %invocation of  $o.m()$
 has been completed.
\end{definition}%
This would mean that we need to keep track of call locations,
in the analysis. (Or alternatively we could consider calls of a given  \emph{future variable}.)
}

\ignore{
Thus it suffices that 
each iteration of the cycle will produce 
one call to an object $o$ and that there is nothing in the cycle that
ensures that the  result of this call is read or is produced.

If the flooded object is outside the group this means that there must
be a \emph{get} operation in the cycle, which directly or indirectly ensures
that a future from the generated calls is read.  If the flooded object
is inside the group %this means that
 there must be a \emph{get} operation or a
guard in the cycle that ensures that the operation is completed.

We will below focus on the case that the flooded object is outside the
group. This situation is particularly harmful in distributed systems
since the flooding of an object is caused by the environment.  Thus it
cannot easily be detected by unit testing. (In contrast, when the
flooded object is inside the group unit testing of the group may
reveal the problem.)  
}
Flooding of this kind may depend on the relative
speed of different objects, and  may be difficult to detect even
by testing of complete systems, due to their inherent
non-deterministic nature.  They may show up for instance at times when
the system load is high.

%Therefore static detection of possible flooding is worthwhile.


The top-level view of an algorithm to detect flooding-cycles is shown in figure \ref{flow-analysis}.
We first create a control flow graph for each method where the nodes are method start nodes, method calls, \emph{get} statements, 
\emph{await} statements,
or \emph{put} statements (including implicit \emph{put} statements at the end of Void methods).
All other statements are ignored. 
In addition, the nodes are of two types,
synchronous, or asynchronous. Synchronous nodes are \emph{get} statements or \emph{await} statements.
(Need to look at an example with synchronous method calls.
\footnote{
A synchronous call should not pose problems in itself, but its body may make 
problematic asynchronous calls. And \emph{get}s in its body should count in the same manner as \emph{get}s in the calling method. So I guess an explicit \emph{get} would work, as Charlie indicated by email.}
The Oi from a synchronous method call needs to include any asynch calls
resulting from the execution of the method.)

\begin{figure}
\begin{shaded}
\begin{enumerate}
\item Build the individual control flow graphs for each method including a start node, and a node for each call, \emph{get}, \emph{await}, and \emph{put} statements.
\item Add call edges from call nodes to the start node of the corresponding method.
\item Identify any cycles in the graph.
\item Use flow analysis to compute the \emph{put} edges from \emph{put}s to \emph{get}/\emph{await}. (What is going to happen with more complex examples
where there are multiple \emph{put}s that might reach a given \emph{get}?)
\item Use flow analysis to identify any flooding cycles.
\end{enumerate}\end{shaded}%
\caption{\label{flow-analysis}
Flow Analysis for Detecting Flooding-Cycles}
\end{figure}

In step 2 we connect the cfgs for each method with call edges. Note that we do not distinguish between objects, only classes.

In step 3 we identify any cycles in the graph.

In step 4 we add edges from \emph{put} statements to \emph{get} or \emph{await} statements that might block on the value for that future.\footnote{If we have the ambition of ensuring that 
there is no flooding when the algorithm finds none,
we must ensure that a ``get'' actually waits for the future
(``must instead of ``might'').}

If there is a cycle that creates futures (including implicit Void futures for trivial calls) that are not read
in the cycle, then there is a flooding-cycle with respect to the call that produced the unread future.

After step 4 we will have a graph with start nodes, call nodes, \emph{get}/\emph{await} nodes, and
put/return nodes. We will have flow edges (within a method), call edges (between methods), and \emph{put} edges from \emph{put}/return
to \emph{get}/\emph{await}.

Step 5 analysis then proceeds by picking a method start node that is part of a cycle.
For each (in some order? Breadth First? Does it matter?\footnote{It should not matter since the we repeat until no further changes!}) flow node $N_i$ with input edge sets $P_{i,j}$, the output set $O_i$ is
computed as shown in figure \ref{step5}. The sets $O_i$ are a modified multi-set. These are like regular sets except that an entry may be modified with
a $*$ as in $C.m^*$ indicating that $C.m$ appears in the set ``more than once.'' For these modified multi-sets, 
\begin{eqnarray*}
\{X\} + X & = & \{X^*\},\\
\{X^*\} - X & = & \{X\},\\
\{X^*\} \bigcup \{X\} & = & \{X^*\}, and \\
\{X^*\} \bigcap \{X\} & = & \{X\}
\end{eqnarray*} 
In figure \ref{step5},  $Cancel(S)$ is $S$ with the following changes:\newline
If $S$ contains both $C.m$ and $\overline{C.m}$ remove them both.\newline
If $S$ contains both $C.m^*$ and $\overline{C.m}$ then remove them both and add $C.m$.

% I think I need to have more proper multisets and do Cancel on each Pi before combining them for Oi.
% The union over Pi's however does a sort of max for multiples. So {X_2} U {X} is just {X_2} not {X_3}.

\begin{figure}
\begin{shaded}
if the node is an async call to $C.m$, $O_i \leftarrow Cancel(\bigcup_j P_{i,j} + C.m$)\newline
else if the node is a \emph{get}, $O_i \leftarrow \bigcup_i P_{i,j}$\newline
else if the node is a \emph{put}, \newline
\hspace*{.5cm}  $O_i \leftarrow \{ \overline{C.m} \}$ where C.m is the start node of method containing the \emph{put}\newline
AND $O_k \leftarrow O_k + \overline{C.m}$ for each $O_k$ that is the output set of an immediate predecessor to the current \emph{put} node\newline
otherwise $O_i \leftarrow Cancel(\bigcup_j P_{i,j})$\newline
Repeat until there are no further changes in any $O_i$.%\newline
\end{shaded}%
\caption{\label{step5}%
Flow analysis (step 5) for finding flooding cycles from the graph,
computing the output egde set $O_i$ for a node $i$ from its input edge sets 
$P_{i,j}$.
}
\end{figure}
\footnote{The AND-part could be replaced by:
%\begin{quote}
%\begin{shaded}
For every node with $\{ \overline{C.m} \}$ in its output,
$\{ \overline{C.m} \}$ should propagate to all its outputs and also to its input sets, 
%(in not already there)
provided the node represents a  non-blocking and non-suspending statement.
%\end{shaded}\end{quote}
This may be needed for instance if there are 
trivial statements (say an asynchronous call)
between the cycle and the \emph{get}.
We may then need to cancel less often,
and we detect a potential flooding-cycle if a call
%$O.m()$ 
is a member of every  $Cancel(O_j)$ in the cycle.
}

%=======================================================
\subsection{New Alternative Flow Analysis (step 5)}

\textbf{Assumptions:}

\begin{itemize}
\item
The calls in the graph are labeled, 
say numbered by their textual occurrence in the (sub)program.
\item
 We consider one cycle (at a time),
ignoring any external call initiating the cycle.
\item
If the same method is called several times from within the cycle,
we include a copy of its body for each call.
Thus each copy of a  method body has  at most  one caller from within the cycle.
\item
We assume a finite graph (even after expansion).
\item 
A  \emph{put} node of a copy of a method body, is marked with the 
caller $n$, marking that the call is completed.
\item
We assume each \emph{get}  node,
and each \emph{put} node, possibly
possibly outside the cycle, 
can be traced back to a unique call $n$ creating the call,
and we mark each  \emph{get} node and each  \emph{put} node  with the corresponding call  $n$, marking that the call is 
completed.
Note, in this analysis other parts of the program graph may be needed!
\item
Blocking calls are split into an async call $n$ and a (matching) \emph{get}
marked with  $n$.
\item
We treat blocking self-calls specially,
by not including an edge from the call node to the get node,
but instead  in-lining  the copy of the method
 (with an arrow to its
start node, and an arrow from each  \emph{put} node
back to the next statement).
\item
Boolean \emph{await} statements are represented as nodes in the graph
(since they may affect method completion).

\end{itemize}
\textbf{Analysis:}
The analysis considers one cycle (at a time)
together with surrounding parts of the program graph.
The analysis will collect sets of calls $n$ from the cycle and call completions,
in  the cycle, or even outside  the cycle when  reachable from the cycle without suspensions or blocking,
or  when a predecessor of  a \emph{get} is related to a call in the cycle.
The analysis, uses two sets, denoted $calls$ and $comps$.
\begin{itemize}
\item For each call $n$ in the cycle add $n$ to $calls$.
\item For each \emph{get} node  marked   $n$ in the cycle add   $n$ to  $comps$.
\item For each \emph{put} node  marked   $n$ in the cycle  add   $n$ to  $comps$.
\item  For each \emph{put} node marked   ${n}$ reachable along flow edges from the cycle, 
without going through \emph{await} or  \emph{get} nodes,
 add   ${n}$ to  $comps$.
\item  For each \emph{get}  marked   ${n}$ 
leading to a \emph{put}  node
related to a call in the cycle,
 add   ${n}$ to  $comps$.
%\item
%\item
\end{itemize}
The cycle is \emph{flooding wrt a call} $n$ if 
$n\in (calls -comps)$.
\ignore{
\subsection{Previous Version of Alternative Flow Analysis (step 5)}


\textbf{Assumptions:}

\begin{itemize}
\item
A start node of method $m$  has no label,
but the \emph{put}s of the method 
is labeled by the special label $m$
(in case of several methods $m$ in the program, we may use the class name
to distinguish the different $m$s as in $m_C$).
\item
The edges are marked by sets of labels.
\item
We assume each \emph{get} can be traced back to a unique call $n$
and \emph{put} node generating the future value,
We then make an edge labeled $\{n\}$ from the \emph{put} node to the \emph{get} node.
(We may perhaps need several copies of a method
if that helps?)%
\footnote{
If a \emph{put} note may lead to several \emph{get} nodes, depending on how they are
called, we may take several copies of the method so that each \emph{put}
unique binds to a  call.}
\item
Blocking calls are split into an async call $n$ and a (matching) \emph{get}
associated with $n$.
There is an edge labeled  $\{n\}$ from the \emph{put} of the called method to the \emph{get},
other edges from the \emph{put} node should not be affected by this call $n$.
\item
We treat blocking self-calls specially,
by not including an edge from the call node to the get node.
\ignore{%I guess blocking self-calls are treated specially, 
say in-lining (a
copy) of the called method in the cycle (with an arrows to its
start node, and an arrow back to the next statement).

(For blocking self calls, I guess the next node is the
 start node of (a copy) the 
called method where \emph{put} connects back to the next statement(?)
This  means that several copies of the same body may appear in the 
analysis if they end up differently.}
\item
Boolean \emph{await} statements are represented as nodes in the graph
(since they may affect progress and thereby \emph{put}-propagation).
\end{itemize}
\textbf{Analysis:}



%Call statements are labeled by unique positive numbers and
%put statements are labeled 0.
%Start nodes have no label and are not recorded in the analysis.
Each edge between nodes in a cycle is assigned  a set of labels,
initially empty.
Each node has one or more outgoing edges, each labeled with the same edge set, 
called its \emph{output set},
except for \emph{put} nodes where the different outgoing edges should have
only one label in the set.
%set for each outgoing nodes,
%but 
A node may have several edges coming in, each with different label sets,
called its  \emph{input sets}.
The flow analysis
considers \emph{each cycle} and 
 is done in two phases,
(assuming edges from \emph{put} nodes has been made and labeled as mentioned):
\begin{enumerate}
\item
a backwards analysis inside each method body, handling 
backward propagation of \emph{put} labels,
 and 
\item
a forward analysis through the graph, 
handling forward propagation of call labels.
\end{enumerate}
Details are given in figure \ref{step5a}.
Note that since we consider one cycle at a time,
each node has at most one undotted input edge and one 
undotted output edge.




\emph{NOTE:} There are no stars, % and complement/overline,
so detection of flooding calls for a cycle should be easy.
Flooding is detected when a call label is present
on all edges in the cycle after applying the \emph{Cancel} function:
\begin{quote}
  $Cancel(S)$ is $S$ with the following changes:\newline
If $S$ contains both $C.m$ and $\overline{C.m}$ remove them both.
\end{quote}

\begin{figure}
\begin{shaded}

\textbf{Backward propagation (methodwise):}
Start with a \emph{put} node inside  a method $m$. 
%The termination statement(s) (i.e., a \emph{put}) of the  body  a method $m$ 
Its  label $m$  is propagated backwards 
inside the method body, until it reaches 
a node representing an
\emph{await} statement or a \emph{get}.
Thus, for each such node, if  $m$ is in %one of
 its output set it is 
propagated to  its  input edge. %all input edges of the node.



\textbf{Forward propagation (cyclewise):}
Inherit the result of the backward phase, consider a given cycle 
and 
start with a start node. 

When entering the body of a method  $m$, store the set of 
predecessor nodes \emph{of this cycle} (they will all be call nodes,
typically only one)
in a  set $caller_m$.

When passing a call node $i$, %representing a call inside a method body $m$, 
add its label $n$ to the output edge set:
$$\begin{array}{lll}
O_i&\leftarrow& O_i \bigcup_j cancel_m(P_{i,j}) + n%\\
\end{array}$$
where $m$ is the enclosing method and $cancel_m$ is given by
$$\begin{array}{lll}
cancel_m(S)&= S - caller_m,& \textbf{if}\ m\in S\\
cancel_m(S)&= S , &\textbf{if}\ m\not\in S%\\
\end{array}$$
% 
\ignore{If the node is a \emph{put} (ending method $m$)
$$\begin{array}{lll}
O_i&\leftarrow& O_i \bigcup_j P_{i,j} - \{m\} %\\
\end{array}$$}
%
If the node is a \emph{get} associated with a call $n$
$$\begin{array}{lll}
O_i&\leftarrow& O_i \bigcup_j  cancel_m(P_{i,j}) + \{{n}\}%
\end{array}$$
This assumes that it is detected that the \emph{get} is getting the future
defined by the call $n$.
%\footnote
{NOTE: No problem with termination  now,
since the call-get  connection is given and thus $n$ will never be 
in the output  of the node. (Right?)}
In all other cases (including \emph{put})
$$\begin{array}{lll}
O_i&\leftarrow& O_i \bigcup_j cancel_m(P_{i,j}) %\\
\end{array}$$
Repeat until there are no further changes in any $O_i$.%\newline
\end{shaded}%
\caption{\label{step5a}%
Alternative flow analysis (step 5), based on call statement labels, for finding flooding cycles from the graph,
computing the output edge set $O_i$ for a node $i$ from its input edge sets 
$P_{i,j}$.
}
\end{figure}

}
\subsection{Old Text}

\begin{definition}
\label{potential-flooding-cycle}
There is a \em{potential flooding-cycle} between cycle $C_i$ and call $O.m()$ if 
$O.m()$ or $O.m*()$ is a member of every set $O_j$ in the cycle, and
the start node for $O.m()$ is not in $C_i$.
\end{definition}



\begin{figure}[t]
\includegraphics[width=15cm]{graphOrig}
\caption{\label{graph-orig}
The graph and output sets after the completion of step 5 for the original version of the program (figure \ref{example-subscr}).
}
\end{figure}

\begin{figure}[t]
\includegraphics[width=15cm]{graphModified}
\caption{\label{graph-modified}
The graph and output sets after the completion of step 5 for the modified version of the program (figure \ref{example-subscr-flooding}).
}
\end{figure}


Figures \ref{graph-orig} and \ref{graph-modified} show the state of the graph and the output sets
after the completion of step 5 for the two versions of the producer consumer problem above. To conserve space, all method names are abbreviated to the
first letter of the class and the first letter of the method except that we use X for the class Proxy it further disambiguate it from Producer. 
For example, Producer.detectNews is Pd and Proxy.publish is written Xp.

In figure \ref{graph-orig} we see that Cs (Client.signal) appears in every set of cycle A. This indicates that cycle A is a potential flooding-cycle
with respect to Client.signal. In practice this cycle does not cause a flood because in this implementation, the amount of work required by the
Client to complete a signal call is trivial and thus the Client objects easily keep up with the calls. Also, the rate of execution for cycle A is
limited by the actual arrival of news items from the NewsProducer, which further limits the rate at which this cycle generates asynchronous calls to
CLient.signal.

In figure \ref{graph-orig} we also see that Xp (or Xp*) appears in every set of cycle B. However, because
the start node for Xp is in cycle B, this is not a flooding cycle. We can see that it is in fact not a flooding cycle 
because although each time around the cycle generates a call to Xp, each time around the cycle also results in the completion of
one call for a net gain of zero. Even if Proxy objects are distinct (as they in fact are in this example), this would only cause 
a flood if each of the Xp calls was somehow delayed for a non-trivial amount of time after issuing the asynchronous call as the 
last step in the method Xp.

In the modified version of the program as reflected in figure \ref{graph-modified} there is an additional flood between cycle A and
Pd (Producer.detectNews). This flooding-cycle is serious, and in practice will flood the system almost immediately.
Unlike in version 1, there is no \emph{get} regulating the speed at which cycle A cycles. Furthermore, the Pd calls are dependent upon the
arrival of news items not simply limited by processor execution speed.


\bibliographystyle{abbrv}
%\bibliographystyle{alpha} 
\bibliography{creol,ref}
%\bibliography{extracted}


\end{document}
============================= end of file ====================================


output sets written after each statement, label before colon
  Sp  3 
1:Pd  1,3
2:Xp  1,2,3
           put-Sp
  Xp  1,2,3
  Get 1,~1,2,3
3:Cs  1,~1,2,~2,3
4:Sp  1,~1,2,~2,3
          put-Xp
