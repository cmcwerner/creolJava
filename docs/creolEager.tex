\documentclass[12pt]{article}%[preprint],%a4paper,English
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{framed}
\usepackage[normalem]{ulem}

\pdfoutput=1

\input{preamble}

	
\renewcommand{\qedsymbol}{\rule{1ex}{1ex}}
\definecolor{shadecolor}{rgb}{0.9,0.9,0.9}
\newcommand{\Blue}[1] {\textcolor{blue}{#1}}%{\textsf{#1}}%
\input{definitions}    
\input{opsemDefs}
%
\newcommand{\knip}{\vspace{-1.5mm}}
\newcommand{\OLDFOOT}[1]{}%{\OO{TODO: #1}}
%\newcommand{\IFLONG}[1]{}%{\OO{TODO: #1}}
\newcommand{\TODO}[1]{}%{\OO{TODO: #1}}
\newcommand{\oo}{object-oriented\xspace}%{\textsf{#1}}%
\newcommand{\get}{get\xspace}%{\textsf{#1}}%
\renewcommand{\NEW}[1]{#1}%{\Blue{#1}}%{\textcolor{blue}{\textit {#1}}}%{\textsf{#1}}% {#1}
%\renewcommand{\RED}[1]{\textcolor{magenta}{#1}}
\newcommand{\callsE}{\ensuremath{\mathit{calls_C^{R}}}\xspace}% from Executions
\newcommand{\callsD}{\ensuremath{\mathit{calls_C^{S}}}\xspace}%  from Detection
\newcommand{\compsE}{\ensuremath{\mathit{comps_C^{R}}}\xspace}% from Executions
\newcommand{\compsD}{\ensuremath{\mathit{comps_C^{S}}}\xspace}%  from Detection
%\begin{frontmatter}

\begin{document}

\title{On Detecting Over-Eager Concurrency  \\
       in  Asynchronously Communicating  \\
       Concurrent Object Systems%
\thanks{This work was done in the context of the EU projects
   FP7-610582  \emph{Envisage: Engineering Virtualized Services}
    (\texttt{http://www.envisage-project.eu}) and
FP7-ICT-2013-X \emph{UpScale: From Inherent Concurrency to Massive 
Parallelism through Type-based Optimizations}
  (\texttt{http://www.upscale-project.eu}).}}

\author{Charlie McDowell and Olaf Owe\\
 \small{University of California, Santa Cruz, Dept.\ of Computer Science, USA, }\\
 \small{and University of Oslo, Dept.\  of Informatics Norway} 
 }
\date{\today}
\maketitle

\lstset{language=ABS}
\lstset{basicstyle=\ttfamily}
\ignore{
\lstset{backgroundcolor=\color{codebg}}
\lstset{frame=single}
\lstset{framesep=10pt}
\lstset{rulecolor=\color{codeframe}}
\lstset{upquote=true}

}

\lstset{emph={awk}, emphstyle=\textbf}

\section{Introduction}


Today, concurrency is a key aspect of the computer systems forming our
infra-structure. It is essential in distributed systems and net-based
service systems such as cloud computing, %, but also in multi-core systems
%applications.  
as well as % in % and also in %order to exploit 
multi-core computers.
\OO{Since  it is easier to reduce parallelism} than to increase the amount
of parallelism, 
it is a non-trivial 
challenge to design systems that 
allow %exhibit %exploit %work with
the desired amount of concurrency --  and in a correct manner.  In
practice many systems rely on centralized control or
synchronization of blocks of code to
make programs dealing with shared data work correctly, including
thread-based object-oriented concurrency, which is %form %are
the most common paradigm used to program distributed systems today.  
However, synchronization restricts parallelism
and slows down overall performance.  
%\sout{The thread-based concurrent model suffers from this.}
While synchronization 
primitives for notification/signaling may improve efficiency, they 
%Thread-based object-oriented concurrent programs suffers from this, and 
%in addition the synchronization primitives based on waiting and notification 
are difficult to use correctly because they break modular reasoning and
understanding.

The actor model has been acknowledged as a natural way of programming
concurrent systems, and is based on a simple semantics allowing
modular reasoning \cite{Hewitt77,Agha86,DAghaT04,218170}.  It has been
extended to the object-oriented setting in the form of active
concurrent objects, interacting by means of remote method calls.
Asynchronous methods increase efficiency by allowing non-blocking calls;
and shared futures enable even more efficient interaction, allowing
objects to share computation results without waiting for the results
\cite{Yonezawa86,Halstead85,liskov88pldi}. For instance a caller who
does not need the result of the called method may pass the future
identity of the result to other objects without (itself) waiting for the
result to appear.

Inter-object concurrency comes for free in the sense that each object
can run concurrently with other objects.  Intra-object synchronization
is handled in a modular manner without the use of external notification.
The concurrency model allows unrestricted concurrency with a
compositional semantics. Thus it enables %simplifies
efficient programming, class-wise understanding, verification, and testing.
However, this unrestricted concurrency model
does not come without a price.  This
programming style may give rise to deadlocks, and it is easy
%  Although not unique to programs created using Creol style synchronization,
% this programming style does make it quite easy 
to create programs that are class-wise semantically
correct but that fail due to over-eager creation of %suspended 
method calls. A system may feed an object with more calls than it is
able to handle, regardless of its processing speed.  We refer to this
situation as \emph{flooding} of the object.

While analysis of deadlock situations for this concurrency model has
been investigated in several ways, we are not aware of analysis of
object flooding for this concurrency model. In this paper we define
and exemplify the concept of flooding, distinguishing between strong
and weak flooding.  The scientific contribution of the paper is to
propose a static analysis method to detect possible flooding
situations, and prove its soundness (no false negatives).  Since 
static analysis of flooding cannot be both sound and complete,
detection of flooding may not imply a real flooding situation.
However, when no flooding is detected, this
%on of no flooding
 implies that there are no real flooding situations (soundness).

Something on related topics, like process management and process balancing...
data race detection.

We ignore flooding caused by direct recursion,
since this is not considered a concurrency problem.

\begin{figure}[t!]
$$
%
  \begin{array}{lrl@{\hspace{1em}}l} 
    \ifdecl & \bnfdef & 
    \kw{interface}\ I\ \bnfoptional{\kw{extends}\ \bnfplus{I}}^? 
%    \{\many{M_s}\} 
    \{S^*\} 
    & 
    \text{interface declaration} 
    \\ 
    \cldecl & \bnfdef & \kw{class}\ C([\cpofT]^*
    )\
    \bnfoptional{\kw{implements}\ \bnfplus{I}}\ \\ & & 
  \{[\wofT  \ [:=e]^?]^*
    \
    \bnfoptional{
    s
    %\CD{\{w := \new \ C(\elist{e})\}}
    }^?\
    %\many{M}
    M^*
\}&   \text{class definition} 
    \\  
%%%%      
%    \cldecl & \bnfdef & \kw{class}\ C([\cpofT]^*)\
%	%\bnfoptional{
%	\kw{implements}\ \bnfplus{I}
%	%}
%	\    
%    \{[\wofT \ [:=e]^?]^*\ M^*\}
%    &   \text{class definition} 
%    \\ 
%    M & \bnfdef & T\ m ([\xofT]^*)\ \{ [\kw{var}\ [\xofT]^*]^?\ s\;;\ \RETURN \ e\}
%    & \text{method definition} 
%    \\
    M & \bnfdef & 
    S\ B
	& \text{method definition} 
    \\
    S & \bnfdef & T\ m ([\xofT]^*
    )&  \text{method signature} 
    \\ 
    B & \bnfdef & \{[\kw{var}\ [\xofT \ [:=e]^?]^*;]^?% \many{\xofT}
    \ [s;]^?\ \PUT \ e\} & \text{method blocks} \\    
    T & \bnfdef & I %C
 \bnfbar \Int \bnfbar \Bool \bnfbar \String \bnfbar \Void \bnfbar \Fut{T}
    &  \text{types} \\
    v & \bnfdef & x \bnfbar w 
    & \text{variables (local or field)} 
    \\ 
    e & \bnfdef &  \kw{null} \bnfbar \this\ 
    \bnfbar v  \bnfbar cp  \bnfbar f(\elist{e}) &
    \text{pure expressions} 
    \\ 
    s & \bnfdef  & 
     v := e \bnfbar 
     v := v!m(\elist{e})  \bnfbar 
     v := [v.]^? m(\elist{e})         & \text{statements} 
 \\ &&  
    \bnfbar  [\AWAIT]^?   v := \GET \ e  \bnfbar \AWAIT\ e 
 \\ &&
    \bnfbar \kw{if}\ e\ \kw{then} \ s\ [\kw{else}\ s]^? \ \kw{fi} 
    \\ &&
    \bnfbar v := \new \ C(\elist{e})
    \bnfbar  \kw{skip} \bnfbar s;s  
\\
\end{array}
$$
\caption{\label{fig-creol} Core language syntax, with $C$ class name,
  \cp formal class parameter, $m$ method name, $w$ fields, $x$ method
  parameter or local variable, and where $\frv$ is a future variable.
  We let $[~]^*$, $[~]^+$ and $[~]^?$ denote repeated, repeated at least
  once and optional parts, 
  respectively, and $\elist{e}$ is a (possibly empty) expression list.
  Expressions $e$ and functions $f$ are side-effect free.}
\end{figure}



\section{A core language}

We consider a minimal core language inspired by Creol and its
successor ABS
\cite{Johnsen04b,johnsen07sosym,Johnsen05d,HATS1.2}. %Johnsen04e,
The Creol language
exploits the paradigm of concurrent, object-oriented,  active objects
using remote method call and  asynchronous method calls as the interaction
mechanism, adding support for non-blocking method calls to avoid
unnecessary waiting.  Shared-variables as well as 
 thread-based notification are
%replaced by a
avoided, introducing a
release mechanism, allowing an object to perform other tasks while
waiting for a condition to become true or for a method result to
appear.  Local data structures are captured by abstract data types
rather than (concurrent) objects.
% Modular semantics and modular understanding and reasoning are
% possible, and thus an object can be tested in isolation since its
% semantics is not changed by its environment.  
The resulting paradigm has a compositional semantics  and supports
modular reasoning and understanding of classes, and thus an object can
be tested in isolation since its semantics are not changed by its
environment \cite{Johnsen08,Din12jlap,din12sefm}.
\ignore{
Creol (and others) have suggested the use of concurrent objects
communicating via asynchronous method calls and futures, as a pathway
to better reasoning about concurrent systems. 

The communication and
synchronization model of Creol simplifies deadlock detection, allows
for ...

However, these advantages do not come without a price.  Although not unique to
programs created using Creol style synchronization, this programming
style does make it quite easy to create programs that are semantically
correct but that fail due to over eager creation of suspended method
calls.}


%The syntax of our core language is given in figure \ref{fig-creol}.


The core language presented in figure \ref{fig-creol}
includes standard
statements for assignment, \kw{skip}, conditionals, and sequential
composition.  We use a Java-like syntax, but use := for assignments.
%to not confuse 
%basic statements for first-class futures.
Methods are organized in interfaces and classes in a
standard manner.  A class $C$ takes a list of formal  parameters
$\classpar$, and defines fields $\Att$, optional initialization statements $\elist{s}$, and methods $\many{M}$.  
There is read-only access to 
%class parameters $\classpar$,
% method parameters $\many{x}$, and implicit variables, such as
 \this, referring to the current object, as well as %and 
the implicit method parameter \destiny, referring  to the future of the call
of the current method.
A method definition has the form $m (\elist{x})\{\kw{var }\elist{y};\
s;\ \PUT\ e\}$, when ignoring type information, where $\elist{x}$ is
the list of formal parameters, $\elist{y}$ is an optional list of
\emph{method-local variables}, $s$ is a sequence of statements, and
the final 
\emph{put} statement writes
the value of $e$ %s put 
in the future of the call, ``resolving the future''.
%
A future variable $\frv$  declared by $\Fut{\im{T}} \frv$  may refer to
%ndicating that $\frv$ may refer to 
futures  containing values  of type
$T$. The call statement $\frv := x!m(\elist{e})$ invokes the method $m$ on
object $x$ with input values $\elist{e}$.  The identity of the
generated future is assigned to $\frv$, and the calling process
continues execution without waiting for $\frv$ to become resolved.  The
query statement $v :=  \GET\ \frv$ is used to fetch the value of a
future. This statement blocks until $\frv$ is resolved, and then 
assigns the value contained in $\frv$ to $v$. 

The non-blocking release statement $\AWAIT \ v := \GET\ \frv$ suspends
the current process as long as $\frv$ is not resolved,
allowing other (enabled) process of the object to continue.
This gives rise to more efficient programming with futures.
Similarly, the statement
$\AWAIT \ c$ %, where $c$ is a 
suspends the current process as long as the Boolean condition $c$ is
not satisfied.
%
The remote call $v :=  x.m(\elist{e})$ blocks while waiting for
the future of the call to be resolved, and may be seen as a 
shorthand for  $\frv := x!m(\elist{e}); v :=  \GET\ \frv$ 
for a fresh $\frv$.
%Similarly 
The construct for local calls, $v:=m(\many{e})$,
employs a standard stack-based execution.

\ignore{
The non-blocking release statements,
$\AWAIT \ c$, where $c$ is a Boolean condition, and
%$\RELEASE$, 
$\AWAIT \ v :=  \GET\ \frv$, 
 release the  current process
%to be able to release the current process.
 as long as 
the condition is not satisfied or 
$\frv$ is not  resolved, respectively.
This gives rise to more efficient programming with futures.}


\ignore{Further statements for process control include a non-blocking
statement
$\AWAIT \ c$, where $c$ is a Boolean condition, and
%$\RELEASE$, 
$\AWAIT \ v :=  \GET\ \frv$, 
which releases the  current process
%to be able to release the current process.
 as long as $\frv$ is not yet resolved. 
This gives rise to more efficient programming with futures.}
%So a more flexible way to query a future will be $\RELEASE; v := \frvq$. 
%The discussion about process releasing statements can be found in
%\cite{din12jlap}. 
%we show how process release statements, including a 
%releasing query statement
% It is possible to add a treatment of 
% %the discussion about 
% process release statements 
% as a straight forward extension of the present work,
% see section 
%following the approach of \cite{din12jlap}.
%without inte violating the other part of the paper.
% where the issues related to futures are the main concern. 
%However, %we choose to focus on a  general  set of \ABS 
%
Object variables are typed by interfaces, 
and remote field access is (syntactically) forbidden.
We assume that call and query statements are
well-typed.  
\ignore{If $x$ refers to an object where $m$ is defined with 
input types $\many{S}$
% no input values 
and return type $T$, the following code is well-typed
when $\many{e}$ is of type  $\many{S}$:
$\Fut{T} \frv;\ T\ v;\ \frv:=x!m(\many{e});\ v:=\frvq$,
which represents 
a traditional synchronous and blocking method call.
This call is abbreviated by the notation $$v:=x.m(\many{e})$$
%In the example below
%We use the notation $$v:=x.m()$$ to abbreviate this call.
Note that the call $v:=\this.m(\many{e})$ will block,
and thus a construct for local calls, say  $v:=m(\many{e})$,
would be useful.}
% Class instances are concurrent, encapsulating their own state and
% processor.  Each method invoked on the object leads to a new process,
% and at most one process is executing on an object at a time.  Object
% communication is \emph{asynchronous}, as there is no explicit transfer
% of control between the caller and the callee. 
We here ignore inheritance since it
does not influence our discussion on flooding.



\section{Flooding Cycles}

As a motivating example we will
consider  versions of the publish/subscribe example.
%taken from \cite{din14jlap}.
Clients may  \lstinline{subscribe} to a service object
and the service object will ensure 
that subscribing objects receive information about ``news''.
Clients are notified by news by 
%The interface of Clients contains
 the   \lstinline{signal} method.
%for this purpose. 
%Clints call \lstinline{subscribe} on the 
The service object is using a number of proxies to 
handle all the clients and is using  an underlying news producer
to obtain news. The service object is using futures to avoid
being delayed by waiting for news to be available,
thus it may continuously respond to clients.
The  interfaces of these units are given 
in figure \ref{example-subscr-interfaces}.

\begin{figure}
%Example
\begin{abs}
data News=E1|E2|E3|E4|E5|None;    $\hfill$ // example of different news
interface ServiceI{
  Void subscribe(ClientI cl);     $\hfill$ // called by Clients
  Void produce()}                 $\hfill$ // called by Proxies
interface ProxyI{
  ProxyI add(ClientI cl);         $\hfill$ // called by Service objects
  Void publish(Fut<News> fut)}    $\hfill$ // called by Service objects
interface ProducerI{
  News detectNews()}              $\hfill$ // called by Service objects
interface NewsProducerI{
  Void add(News ns);              $\hfill$ // called by main when news arrive
  News getNews();                 $\hfill$ // called by Producer objects
//  List<News>getRequests()}     // not used !
interface ClientI{
  Void signal(News ns)}           $\hfill$ // called by Proxies
\end{abs}
\caption{\label{example-subscr-interfaces}
The interfaces to complete the subscription example.}
\end{figure}
 %=========================================

A high-level Creol implementation of 
%the example of
 the publish/subscribe model is given in 
figure \ref{example-subscr} and is taken from Din and Owe\cite{din14jlap}.


\begin{figure}
%Example
\begin{abs}
class Service(Intlimit,NewsProducerInp) implements ServiceI{
  ProducerI prod;ProxyIproxy;ProxyIlastProxy;
  { prod := new Producer(np); 
    proxy:= new Proxy(limit,this);lastProxy:=proxy;this!produce()}
  Void subscribe(ClientIcl){lastProxy:=lastProxy.add(cl)}
  Void produce(){var Fut<News>fut:=prod!detectNews();proxy!publish(fut)}}

class Proxy(Intlimit,ServiceIs) implements ProxyI{
  List<ClientI> myClients:=Nil;ProxyInextProxy;
  ProxyI add(ClientIcl){
    var ProxyI lastProxy=this;
    if length(myClients)<limit then myClients:=appendright(myClients,cl)
    else if nextProxy==null then nextProxy:= new Proxy(limit,s) fi;
             lastProxy:=nextProxy.add(cl) fi;
    put lastProxy}
  Void publish(Fut<News>fut){
    var News ns=None;
    ns =get fut; myClients!signal(ns);
    if nextProxy==null then s!produce() else nextProxy!publish(fut) fi}}

class Producer(NewsProducerI np) implements ProducerI{
  News detectNews(){
    News news:=None;
    news:=np.getNews(); put news}}
class NewsProducer implements NewsProducerI{
  List<News>requests:=Nil;
  Void add(News ns){requests:=appendright(requests,ns)}
  News getNews(){
    var News firstNews:=None; await requests /= Nil;
    firstNews := head(requests);requests:=tail(requests); put firstNews}
 }

class Client implements ClientI{
  Newsnews:=None;
  Void signal(News ns){news:=ns}}

\end{abs}
\caption{\label{example-subscr}
A simple subscription example.}
\end{figure}
 %=========================================

Modifying Client and Proxy as shown in figure \ref{example-subscr-flooding}, results in a program that will flood the system with suspended calls. 
The changes are at lines 9 and 14 in the revised code.
The change is to shift requiring the actual news to have arrived from the Proxy (\lstinline{ns=get fut; myClients!signal(ns);})
to the Client (\lstinline{news:=get fut}).


\begin{figure}
%Example
\begin{abs}
class Proxy(Intlimit,ServiceIs) implements ProxyI{
  List<ClientI> myClients:=Nil;ProxyInextProxy;
  ProxyIadd(ClientIcl){
    var ProxyIlastProxy=this;
    if length(myClients)<limit then myClients:=appendright(myClients,cl)
    else if nextProxy==null then nextProxy:= new Proxy(limit,s) fi;
    lastProxy:=nextProxy.add(cl) fi; put lastProxy}
  Void publish(Fut<News>fut){
    myClients!signal(fut);
    if nextProxy==null then s!produce() else nextProxy!publish(fut) fi}}

class Client implements ClientI{
  News news:=None;
  Void signal(Fut<News> fut){news:=get fut}}

\end{abs}
\caption{\label{example-subscr-flooding}
A flooding variation of the subscription example.}
\end{figure}
 %=========================================

This seemingly minor change, and one that would even seem to make sense in the interest of maximizing concurrency, is in
fact ``too much.'' We might naively take it even one step further and have the client instead do 
\lstinline{news:=await(fut)}, 
which has the additional advantage of allowing the Client to process the news items as they become available, rather then in
the order that the futures were received. In either case, the following sequence of calls can occur, which constitute a
flooding cycle (see definition \ref{flooding-cycle}).
\\

{\small
\samepage
%\begin{center}\begin{flushleft}%{verbatim}
\indent\lstinline{Service.produce} asynchronously calls \lstinline{Producer.detectNews}
\\
\indent\lstinline{Service.produce} asynchronously calls \lstinline{Proxy.publish}
\\
\indent\lstinline{Proxy.publish} asynchronously calls \lstinline{Client.signal}
\\
\indent\lstinline{Proxy.publish} asynchronously calls \lstinline{Service.produce}
%\end{flushleft}\end{center}%{verbatim}
}\\

\noindent
Each pass around this cycle, the asynchronous call to \lstinline{Proxy.publish} is processed as part of the cycle (step 3).
However, each pass around this cycle also spawns an asynchronous call to  \lstinline{Producer.detectNews} that is not processed as part of this cycle,
nor is there any attempt to synchronize this cycle with the completion of those calls to  \lstinline{Producer.detectNews}.
Depending upon the speed of
execution of the code along the path of the cycle, such a cycle can create an unbounded number of suspended calls to
\lstinline{Producer.detectNews}.

We call such sequences flooding-cycles. In this paper we present an algorithm to statically identify
programs that contain flooding-cycles. This approach is conservative in that if it reports that a program is free from
flooding-cycles then it is indeed free of such cycles, however, it may report flooding-cycles that are in fact bounded by
program logic, not amenable to static analysis. It will also report flooding-cycles that do not in practice produce an
increasing number of unprocessed calls due to the execution speed of the flooding-cycle. 

A flooding-cycle must always be racing against one or more specific asynchronous calls, either trivial calls (no waiting on
any future from the call) or calls where the resulting future is not read in the cycle, although the future may be passed
to a separate asynchronous call where it is read.  

The version of the program in figure \ref{example-subscr} has a flooding-cycle (cycle B in figure \ref{graph-orig}) 
that is racing against the \lstinline{Client.signal} calls
generated in \lstinline{Proxy.publish}. This will not cause a problem, provided the Client objects are able to process these signal
calls at least as fast as they are being generated. Our algorithm will alert the programmer to this situation, and the
programmer can determine if there is a real problem here, possibly with the aid of some additional program
instrumentation.  

In this case, the flooding-cycle will not create a flood for two reasons that are beyond the ability of our current approach to detect.
First, this cycle is in fact bounded by program logic. The cycle is walking down a finite chain of Proxy objects.
Second, after a finite number of times around the cycle the code will branch and make a pass around the cycle that includes the 
\lstinline{get}
(cycle A in figure \ref{graph-orig})
which results in a delay for more news to actually arrive, thus limiting the speed of cycle A.

The version of the program in figure \ref{example-subscr-flooding}
results in the graph shown in figure \ref{graph-modified}. This second graph is the same as that in figure \ref{graph-orig}
except that the \lstinline{get} node is now in the  \lstinline{Client.signal}
method (not shown in the graph) and there is no \lstinline{get} in cycle A. 
The result is that cycle A in the modified program
is a flooding cycle that is racing against both the
\lstinline{Client.signal} calls and also against the
\lstinline{Producer.detectNews} calls.  This is because rather than
wait in \lstinline{Proxy.publish} for the news to actually be produced
as in the first version (\lstinline{ns=get fut;}),
\lstinline{Proxy.publish} instead simply passes the future out to
another asynchronous call (\lstinline{myClients!signal(fut);}),
eliminating any progress coordination between cycle A and the
\lstinline{Client.signal} calls. Cycle A in this version of the program is more likely to be a
problem because it is not dependent simply on execution speed of some
code but is dependent upon the arrival rate of news items and in
practice will always result in the number of unprocessed calls quickly
growing to system limits.

\section{Identifying Flooding Cycles}

\begin{definition}[Flooding Cycle]\label{flooding-cycle}
A \emph{flooding cycle} is an execution cycle 
containing a call statement
%involving one or more asynchronous calls
%such that for at least one of those calls,  call it $o.m()$ occurring
 at a given program location, such that 
this statement may produce, directly or indirectly, an unbounded number of 
uncompleted
calls to a specific method.
%such that also an unbounded number of those calls are not completed.
%before any of those calls  has been completed.%
\ignore{COMMENT: well some might complete, as long as the number of uncompleted
ones is also unbounded.}
\end{definition}%

Flooding of this kind may depend on the relative
speed of different objects, and  may be difficult to detect even
when testing complete systems, due to their inherent
non-deterministic nature.  They may show up for instance at times when
the system load is high.

Flooding cycles that depend on unfair scheduling
may be avoided with fair scheduling of concurrent activity and
fair scheduling of  tasks inside one unit.
Flooding cycles that exist even with fair scheduling
are more serious, indicating bad programming.
We call such flooding \emph{strong flooding}.
%inherent, serious

\ignore{
%\section{Definition of Strong Flooding Cycles} %p
\begin{definition}[Strong Flooding Cycle]
\label{strong-flooding-cycle}
A \emph{strong flooding-cycle} is an execution cycle 
involving one or more asynchronous calls
such that for at least one of those calls, call it $o.m()$,
an unbounded number of the calls to  $o.m()$ may be produced by the cycle
before any invocation of  $o.m()$ has been completed,
even with fair scheduling between concurrent units and 
(enabled) tasks within each unit.
\end{definition}}

The top-level view of an algorithm to detect flooding-cycles is shown in figure \ref{flow-analysis}.
We first create a control flow graph (cfg) for each method where the nodes are method start nodes, method calls, \emph{get} statements, 
\emph{await} statements,
or \emph{put} statements (including implicit \emph{put} statements at the end of Void methods). %\footnote
Synchronous method calls will be represented as an asynchronous method call followed immediately by a \emph{get}.
All other statements are ignored. 
%In addition, the nodes are of two types,
%synchronous, or asynchronous. Synchronous nodes are \emph{get} statements or \emph{await} statements.

\begin{figure}
\begin{shaded}
\begin{enumerate}
\item Build the individual control flow graphs for each method including a start node, and a node for each \emph{call}, \emph{get}, \emph{await}, 
and \emph{put} statements.
\item Add call edges from call nodes to the start node of a copy of the corresponding method cfg, unless the call is recursive, in which case
create a call edge to the existing start node. Assign each call node a unique label.
\item Identify any cycles in the graph.
\item Use flow analysis to compute the \emph{put} edges from \emph{put}s to \emph{get}/\emph{await}. (What is going to happen with more complex examples
where there are multiple \emph{put}s that might reach a given \emph{get}?)
\item Compute the calls and comps sets for each cycle to identify flooding-cycles using algorithm xx.
\end{enumerate}\end{shaded}%
\caption{\label{flow-analysis}
Top Level Algorithm for Detecting Flooding-Cycles}
\end{figure}

In step 2 we connect the cfgs for each method with call edges, replicating the method's cfg for each non-recursive call so that we can
associate a specific call with a specific start/get/put. Note that we do not distinguish between multiple calls to the same method in one
object, and one call to a particular method in each of multiple instances of the same class. 
\footnote{Seems like maybe a place for a lemma that asserts that doing so won't result in false negatives.}

In step 3 we identify any cycles in the graph. Note, cycles can include call edges and flow edges.

In step 4 we add edges from \emph{put} statements to \emph{get} or \emph{await} statements that block on the value for that future.
\footnote{If we have the ambition of ensuring that 
there is no flooding when the algorithm finds none,
we must ensure that a ``get'' actually waits for the future
(``must instead of ``might'').}

In step 5 we apply the algorithm in figure \ref{reachable-analysis} to identify any flooding cycles.
If there is a cycle that creates futures (including implicit Void futures for trivial calls) that are not read
in the cycle\footnote{Not really in the cycle, but in the reachable nodes starting from the cycle}, 
then there is a flooding-cycle with respect to the call that produced the unread future. 
%(I guess this is where we introduce a theorem.)


\begin{figure}
\begin{shaded}
\begin{enumerate}
\item Starting with the graph $G$ from step 4 in figure \ref{flow-analysis}, mark all nodes \emph{not reachable}.
\item \label{recompute} Starting with the entry point to the cycle, do a depth-first traversal of $G$ and apply definitions
\ref{defn-sreachable} and \ref{defn-wreachable} to mark nodes as \emph{strongly-reachable}, \emph{weakly-reachable}, or neither.
\item Apply definitions \ref{defn-calls} and \ref{defn-comps} to compute the $calls$ and $comps$ sets.
\item If the previous two steps results in any changes to \emph{strongly-reachable}, \emph{weakly-reachable}, $calls$, or $comps$, 
go to step \ref{recompute}.
\end{enumerate}
\end{shaded}
\caption{\label{reachable-analysis}
Algorithm to compute the \emph{reachable} nodes in a graph relative to a given cycle.}
\end{figure}

%=======================================================
\subsection{Computing the call and comp sets (step 5)}
 We consider one cycle (at a time),
ignoring any external call initiating the cycle.

\noindent\textbf{Assumptions:}

\begin{itemize}
%\item

%\item
%If the same method is called several times from within the cycle,
%we include a copy of its body for each call.
%Thus each copy of a  method body has  at most  one caller from within the cycle.
\item
We assume a finite graph (even after expansion).
\item
The calls in the graph are labeled, 
say numbered by their textual occurrence in the (sub)program.
\item 
\Blue{Every method begins with a \emph{start} node and ends with a \emph{put} node, and those two nodes
will have the same label as the caller. Because of graph expansion, the caller will be unique except
in the case of a recursive call. In that case, the label is the label of the non-recursive caller except when
the cycle being considered includes the recursive call edge.
When the recursive call edge is part of the cycle the label will be that of the recursive caller.}
\item
\Blue{We mark each \emph{get} node with the set of labels corresponding to any \emph{call} nodes that may have
generated the future that reaches the \emph{get}.}
\item
Blocking calls are split into an asynchronous call $n$ and a (matching) \emph{get}
marked with  $n$.
\item
We treat blocking self-calls specially,
by not including an edge from the call node to the get node,
but instead  in-lining  the copy of the method
 (with an arrow to its
start node, and an arrow from each  \emph{put} node
back to the next statement). \Blue{Why do we need this?}
\item We treat \emph{await(future)} the same as a \emph{get}.
\item
Boolean \emph{await} statements are represented as nodes in the graph
(since they may affect method completion). They are assumed to never block when in a cycle and to
always block when not in a cycle.

\end{itemize}
\textbf{Analysis:}
The analysis considers one cycle (at a time)
together with surrounding parts of the program graph.
The analysis computes two sets; the set of calls that could possibly have occurred during 
the cycle or outside of the cycle when \emph{reachable} from the cycle without suspensions or blocking,
and the set of calls that must have completed during
the cycle or outside of the cycle when \emph{reachable} from the cycle without suspensions or blocking.
These sets are denoted $calls$ and $comps$, respectively. An algorithm to compute those sets is shown in
figure \ref{reachable-analysis}.

\ignore{
The analysis considers one cycle (at a time)
together with surrounding parts of the program graph.
The analysis will collect sets of calls $n$ from the cycle and call completions,
in  the cycle, or even outside  the cycle when \emph{reachable} from the cycle without suspensions or blocking,
or  when a predecessor of  a \emph{get} is related to a call in the cycle (NOTE: I don't know what this means.).
The analysis, uses two sets, denoted $calls$ and $comps$. An algorithm to compute those sets is shown in
figure \ref{reachable-analysis}.
}

\begin{definition}[Program Graph]\label{def-program-graph}
A \emph{program-graph} $G$ is a graph comprised of \emph{start}, \emph{call}, \emph{get}, \emph{await}, and \emph{put} nodes,
and \emph{flow}, \emph{call}, and \emph{future} edges, constructed according to steps 1, 2, and 4 of figure \ref{flow-analysis}.
\end{definition}

\begin{definition}[Flow Reachable]\label{def-flow-reachable}
Node $N_j$ is \emph{flow-reachable} from $N_i$ if there is a flow-edge $N_i \rightarrow N_j$. 
\end{definition}

\begin{definition}[Flow Path]\label{def-flow-path}
A \emph{flow-path} is a path made up of only flow-edges.
\end{definition}

\begin{definition}[Strongly Reachable]\label{defn-sreachable}
Node $N_j$ is \emph{strongly-reachable} with respect to cycle $C$ in graph $G$ if
\begin{enumerate}
\item \label{sr-incycle} $N_j \in C$, or
\item $N_j$ is not a \emph{get} node \Blue{or a boolean \emph{await} node}, $N_j$ is flow-reachable from $N_i$, $N_i$ is \emph{strongly-reachable}, and 
no other node $N_k$ is flow-reachable from $N_i$, or
% next rule used in EX14 (quasi example 2)
\item $N_j$ is a \emph{get} node with label set $s$, containing just one label, $n$;
the \emph{put} node with label $n$ is \emph{strongly-reachable};
$N_j$ is flow-reachable from $N_i$; $N_i$ is \emph{strongly-reachable};
and no other node $N_k$ is flow-reachable from $N_i$; or
\item \label{sr-start} $n \in {comps}$, $N_j$ is a start node with label $n$, $\exists$ a call edge $N_i \rightarrow N_j$, and $N_i$ is \emph{strongly-reachable} or

%possible additions
\item $N_j$ is a \emph{put} node with label $n$,
$N_k$ is a \emph{strongly-reachable} \emph{get} node with a label set containing $n$, and the node $call_n$ is \emph{strongly-reachable}.

\item $N_k$ is flow-reachable from $N_j$, $N_k$ is not flow-reachable from any  $N_i$ $i \not = j$, and $N_k$ is \emph{strongly-reachable}.% see Ex9
\end{enumerate}
\end{definition}


\begin{definition}[Weakly Reachable]
\label{defn-wreachable}
Node $N_j$ is \emph{weakly-reachable} with respect to cycle $C$ in graph $G$ if
\begin{enumerate}
\item $N_j$ is \emph{strongly-reachable}, or
\item \label{wr-start} $N_i$ is a \Blue{\emph{weakly-reachable}} start node and there is a flow-path from $N_i$ to $N_j$, or
%\item \sout{$N_i \rightarrow N_k$ is a call edge in $C$ and there is a flow-path from $N_i$ to $N_j$.}

\item\label{wr-calledge} 
\sout{$n \in {comps}$,} $N_j$ is a start node \sout{with label $n$}, $\exists$ a call edge $N_i \rightarrow N_j$, and $N_i$ is \emph{weakly-reachable} or

\item \sout{$N_j$ is a \emph{put} node with label $n$,
$N_k$ is a 
\emph{weakly-reachable} \Blue{(or should that be \emph{strongly-reachable})}
\emph{get} node with label $n$, and the node $call_n$ is \emph{weakly-reachable}.}


%\item $N_j$ is not a \emph{get} node, $N_j$ is flow-reachable from $N_i$, $N_i$ is \emph{weakly-reachable}, and 
%there is no node $N_k$ in $C$ that is flow-reachable from $N_i$, or % don't follow other flow edges for flow edges in the cycle
%\item $N_j$ is a \emph{get} node, all flow-predecessors of $N_j$ are \emph{weakly-reachable}. % no requirement on the put predecessors

\end{enumerate}
\end{definition}

\begin{definition}[Weakly Reachable Calls]
\label{defn-calls}
For cycle $C$, \callsD %\emph{calls(C)} 
is the set of labels of all \emph{weakly-reachable} call-nodes in $C$.
\end{definition}

\begin{definition}[Strongly Reachable Completions]
\label{defn-comps}
For cycle $C$, \compsD %\emph{comps(C)}
 is the set of labels ${n}$ such that 
\begin{itemize}
\item ${n}$ is the label for a \emph{put} node that is \emph{strongly-reachable}, or
\item ${n}$ \Blue{is a member of the set of labels} for a \emph{get} node that is \emph{strongly-reachable}, or 
\item $N_i$ is a \emph{call} node and the head of a call-edge in $C$; 
for every node $N_j$ on a flow-path from $N_i$ to a \emph{put} node,
$N_j$ is not a Boolean \emph{await} node, if $N_j$ is a \emph{get} node then $N_j$ is \emph{strongly-reachable}; 
and $n$ is the label of those \emph{put} nodes.
%Note - I dropped the requirement that the nodes on the paths be WR because that is implied because start_n must be in the cycle making
% it SR and by WR.2 all of the nodes in question will be at least WR.
\end{itemize}
\end{definition}



\begin{theorem}[Flooding with respect to Cycle]
\label{thm-flooding}
If $call_n$ is \emph{flooding} with respect to cycle $C$ then 
flooding is detected by our algorithm, i.e., $n\in (\callsD -\compsD)$.
\end{theorem}


\subsection{Applying the Algorithm to the example program}


\begin{figure}[t!]
\includegraphics[width=15cm]{graphOrig}
\caption{\label{graph-orig}
The graph and call/comp sets for the original version of the program (figure \ref{example-subscr}).
}
\end{figure}

\begin{figure}[t]
\includegraphics[width=15cm]{graphModified}
\caption{\label{graph-modified}
The graph and call/comp sets for the modified version of the program (figure \ref{example-subscr-flooding}).
}
\end{figure}


Figures \ref{graph-orig} and \ref{graph-modified} show the call and comp sets
for the two versions of the producer consumer problem above. To conserve space, all method names are abbreviated to the
first letter of the class and the first letter of the method except that we use X for the class Proxy to further disambiguate it from Producer. 
For example, Producer.detectNews is Pd and Proxy.publish is written Xp.

In figure \ref{graph-orig} we see there are two cycles involving only flow-edges and call-edges.
The call to Client.signal (Cs) is being flooded by both cycles.
This does not produce an actual flood because the amount of work required by the
Client to complete a signal call is trivial and thus the Client objects easily keep up with the calls. 
Also, the rate of execution for cycle A is
limited by the actual arrival of news items from the NewsProducer (\lstinline{await requests /= Nil;}), 
which further limits the rate at which this cycle generates asynchronous calls to CLient.signal.
Also, although not observed by our algorithm, cycle B is in fact finite, as it walks down the chain of Proxies.
We call this \emph{weak flooding}, i.e. flooding that is harmless, given underlying fairness of concurrent objects and
fair scheduling of tasks within an object.

In the modified version of the program as reflected in figure \ref{graph-modified} there is an additional flood of
Pd (Producer.detectNews) by both cycles. This flooding-cycle is serious, and in practice will flood the system almost immediately.
Unlike in version 1, there is no \emph{get} regulating the speed at which cycle A cycles. Furthermore, the Pd calls are dependent upon the
arrival of news items not simply limited by processor execution speed, as indicated by the presence of the boolean \emph{await} in Ng (News.getNews).
We call such flooding \emph{strong-flooding}.

\ignore{
\subsection{Weak and strong flooding}
When a cycle floods with respect to a call $o.m$,
we say that we have \emph{strong flooding} 
when the method contains an  await or get node
(not resolved in the context of the cycle),
otherwise \emph{weak flooding}.
Strong flooding indicates a serious flooding case,
while weak flooding typically indicates flooding 
that is harmless, given underlying fairness of concurrent objects
and  fair scheduling of tasks within an object. 
%Weak flooding of several calls to the same object could cause serious flooding.

The first version of the subscription example
has weak flooding of client calls (\emph{signal}),
whereas the second has strong flooding both with respect to
to client calls and  to \emph{detectNews} calls.
}
%\newpage
%\newpage
\input{proof.tex} %separate file
%\subsection*{Further lemmas}
%\input{charlieProof.tex}


\bibliographystyle{abbrv}
%\bibliographystyle{alpha} 
\bibliography{creol,ref}
%\bibliography{extracted}

\newpage
\section*{Appendix A}

\begin{figure}[ht]
%Example
\begin{abs}
Void cycle()      {1:m(); get$_1$; 2:cycle(); put}
Void m()$\ \ \ \ ${3:n(myfuture); put}
Void n(Future f)  {4:p; get$_4$; get$_f$; put}
\end{abs}
\caption{\label{example-quasi}
A  quasi example to illustrate/test page 9.
Here calls are already labeled and gets are indexed with
a label or future variable. \emph{myfuture} denotes the
future of the current call. The cycle should flood 3 calls.}
\end{figure}

\begin{figure}[h]
%Example
\begin{abs}
Void cycle()      {f:=1:m(); 2:n(f); get$_1$; Put}
Void m()$\ \ \ \ ${...}
Void n(Future f)  {get$_f$; 3: cycle(); put}
\end{abs}
\caption{\label{example-quasi2}
  Quasi example 2.
(As before calls are  labeled and gets are indexed with
a label or future variable.) 
%
Here there should be no real flooding since method
 \emph{cycle} will reach  \emph{put} since call 1 must be completed
due to the   \emph{get} in  \emph{n}.
CALLS: 1,2,3.  
COMPS: 1,2 and also 3 if we put back the (off-cycle)  flow edge into 
 $get_1$.
Without putting it back we do not reach \emph{put} of \emph{cycle}.}
\end{figure}

\begin{figure}[h]
%Example
\begin{abs}
Void cycle(f)      {1:m(f); get$_1$; 2:cycle(f); Put}
Void m(Future f)  {if (bExpr) {get$_f$; 3: n();}  put}
\end{abs}
\caption{\label{example-quasi3}
  Quasi example 3.
%Here 
Method
$n$ could be flooded if bExpr is true.%, but currently we don't mark the call to $n$ as reachable.
}
\end{figure}
\vfill
\end{document}
============================= end of file ====================================


output sets written after each statement, label before colon
  Sp  3 
1:Pd  1,3
2:Xp  1,2,3
           put-Sp
  Xp  1,2,3
  Get 1,~1,2,3
3:Cs  1,~1,2,~2,3
4:Sp  1,~1,2,~2,3
          put-Xp
